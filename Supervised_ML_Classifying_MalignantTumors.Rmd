---
title: "Identifying the Best Machine Learning Algorithm in the Detection of Malignant Tumors"
date: "Sun, 3/27/2022"
output: html_document
---

# Objective

In this project, we'll be analyzing a set of data using three of the methods (of machine learning techniques) learned for classification in the course. 

Load libraries:
```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(ggplot2)
library(rpart)
library(partykit)
library(randomForest)
library(class) # provides KNN function
library(caret)
library(ROCR)
library(GGally)
library(lmtest)
```


# The Data

The physicians have identified a data set that consists of over 500 measurements from Fine Needle Aspiration (FNA) of breast tissue masses. In an FNA, a small needle is used to extract a sample of cells from a tissue mass. The cells are then photographed under a microscope. The resulting photographs are entered into graphical imaging software. A trained technician uses a mouse pointer to draw the boundary of the nuclei. The software then calculated each of ten characteristics for the nuclei. 

The data consists of measurements of the cell nuclei for the following characteristics:

1. radius, 
2. texture,
3. perimeter,
4. area,
5. smoothness (local variation in radius lengths),
6. compactness (perimeter^2/ area - 1.0),
7. concavity (severity of concave portions of the contour),
8. concave points (number of concave portions of the counter),
9. symmetry, and 
10. fractal dimension ("coastline approximation" -1).

Measurements of these ten characteristics are summarized for all cells in the sample. The data set consists of the mean, standard error of the mean, and maximum of the 10 characteristics, for a total of 30 observations for each. Additionally, the data includes an identification number and a variable that indicates if the tissue mass is malignant (M) or benign (B).

Load data
```{r}
fna <- read.csv("FNA_cancer.csv")
glimpse(fna)
```


# The Task

We've been asked by the physicians to conduct an analysis of the data using three of the classification methods.

For our analysis we'll be:

- performing basic exploratory data analysis,
- splitting the data into test and training data,
- build a classification algorithm using decision trees (prune your tree appropriately),
- build a classification algorithm using random forest/ bagging (adjust the parameters of the forest appropriately), and 
- build a classification algorithm using Kth Nearest Neighbors (tune the value of K appropriately).


## Data Pre-Processing and EDA

Convert variable(s) to appropriate variable types
```{r}
fna_tidy <- fna %>% mutate( id = as.character(id), diagnosis = as.factor(diagnosis) )
# Checks each variables data type
sapply(fna_tidy, "class")
```

Descriptive Statistic for each variable
```{r}
summary(fna_tidy)
```

Counts total number of NAs in each variable in the data set
```{r}
na_count <-sapply(fna_tidy, function(y) sum(length(which(is.na(y)))))
data.frame(na_count)
```

Add binary variable for response
```{r}
fna_tidy$diagnosis_binary <- as.factor(ifelse(fna_tidy$diagnosis == "M", 1, 0))
```

Select desirable variables 
```{r}
fna_tidy <- fna_tidy %>% dplyr::select(id, diagnosis, diagnosis_binary, radius_mean, texture_mean, perimeter_mean, area_mean, smoothness_mean, compactness_mean, concavity_mean, concave.points_mean, symmetry_mean, fractal_dimension_mean)

dim(fna_tidy)
```

Check whether data is imbalanced
```{r}
ggplot(fna_tidy, aes(x=diagnosis)) + geom_bar() +
geom_text(stat='count', aes(label=..count..), vjust=-1) + ylim(0,400)
```

Percentage of data as Malignant 
```{r}
sum(as.numeric(as.character(fna_tidy$diagnosis_binary[fna_tidy$diagnosis_binary == 1])))/dim(fna_tidy)[1]*100
```

Correlation between variables
```{r}
round(cor(fna_tidy[4:13]), 4)
```

View Distributions (of raw data)
```{r}
# creating boxplots to check for outliers on all variables 
boxplot(fna_tidy[4:13], names = c("radius","texture","perimeter","area",
                                  "smoothness", "compactness", "concavity",
                                  "concave points", "symmetry",
                                  "Fractal dimension"))

# examines the outliers on all variables by an individual basis
boxplot(fna_tidy[4:5], names = c("radius","texture"))
boxplot(fna_tidy[6], names = c("perimeter"))
boxplot(fna_tidy[7], names = c("area"))
boxplot(fna_tidy[8:13], names = c("smoothness", "compactness", "concavity",
                                  "concave points", "symmetry",
                                  "Fractal dimension"))
```

Variable importance plot (of raw data)
```{r}
regressor <- randomForest(as.factor(diagnosis_binary) ~ . , fna_tidy[3:13], importance=TRUE)
varImpPlot(regressor)
```

Re-scaling appropriate variables between 0 and 1 scale
```{r}
# Function that re-scales the data
rescale_x <- function(x){(x-min(x))/(max(x)-min(x))}

# Creates new data.frame containing re-scaled variables
fna_tidy_rescale <- fna_tidy

# Re-scales the necessarily variables from the data set
fna_tidy_rescale$radius_mean <- rescale_x(fna_tidy_rescale$radius_mean)
fna_tidy_rescale$texture_mean <- rescale_x(fna_tidy_rescale$texture_mean)
fna_tidy_rescale$perimeter_mean <- rescale_x(fna_tidy_rescale$perimeter_mean)
fna_tidy_rescale$area_mean <- rescale_x(fna_tidy_rescale$area_mean)
fna_tidy_rescale$smoothness_mean <- rescale_x(fna_tidy_rescale$smoothness_mean)
fna_tidy_rescale$compactness_mean <- rescale_x(fna_tidy_rescale$compactness_mean)
fna_tidy_rescale$concavity_mean <- rescale_x(fna_tidy_rescale$concavity_mean)
fna_tidy_rescale$concave.points_mean <- rescale_x(fna_tidy_rescale$concave.points_mean)
fna_tidy_rescale$symmetry_mean <- rescale_x(fna_tidy_rescale$symmetry_mean)
fna_tidy_rescale$fractal_dimension_mean <- rescale_x(fna_tidy_rescale$fractal_dimension_mean)

glimpse(fna_tidy_rescale)
```

View Distributions (or re-scaled data)
```{r}
# creating boxplots to check for outliers on all variables 
boxplot(fna_tidy_rescale[4:13], names = c("radius","texture","perimeter","area","smoothness", "compactness", "concavity", "concave points", "symmetry","Fractal dimension"))
```

Variable importance plot (of re-scaled data)
```{r}
regressor <- randomForest(as.factor(diagnosis_binary) ~ . , fna_tidy_rescale[3:13], importance=TRUE)
varImpPlot(regressor)
```


## Train and Test data

Split the data into train and test 
```{r}
set.seed(1997)
n <- nrow(fna)
test_indx <- sample.int(n, round(n*0.2))
train_data <- fna_tidy_rescale[-test_indx,]
test_data <- fna_tidy_rescale[test_indx,]

glimpse(train_data)
glimpse(test_data)
```


## Classification Algorithm using Decision Trees method

Defining diagnosis formula
```{r}
# Creates formula for diagnosis
diagnosis_form <- as.formula(diagnosis ~ radius_mean + texture_mean + perimeter_mean + area_mean + smoothness_mean + compactness_mean + concavity_mean + concave.points_mean + symmetry_mean + fractal_dimension_mean)
```

Decision Tree Method (when cp=0)
```{r}
set.seed(1997)

# Creates decision tree, where pruning is used to avoid overfitting
diagnosis_tree_full <- rpart(diagnosis_form, train_data[c(-1, -3)], cp = 0)

# Creates cp of model 
printcp(diagnosis_tree_full)
plotcp(diagnosis_tree_full)
```

Decision Tree Method after pruning 
```{r}
set.seed(1997)
# Creates decision tree
diagnosis_tree <- rpart(diagnosis_form, train_data[c(-1,-3)], cp = .02)
plot(as.party(diagnosis_tree))

# Creates predictions for diagnosis using the decision tree with the removal of ID, diagnosis, and diagnosis_binary
diagnosis_tree_preds <- predict(diagnosis_tree, newdata = test_data[c(-1,-2,-3)], type = "class")
# Creates Confusion Matrix
confusionMatrix(diagnosis_tree_preds, test_data$diagnosis, mode = "everything", positive ="M")
```


## Classification Algorithm using Bagging and Random Forest method

Bagging Method:
```{r}
set.seed(1997)

# Creates bagging 
diagnosis_bag <- randomForest(diagnosis_form, data = train_data[c(-1,-3)], mtry = 10, ntree = 201)

# Creates predictions for diagnosis 
diagnosis_bag_preds <- predict(diagnosis_bag, newdata = test_data[c(-1,-2,-3)])

# Creates Confusion Matrix
confusionMatrix(diagnosis_bag_preds, test_data$diagnosis, mode = "everything", positive = 'M')

#looking at variable importance
varImpPlot(diagnosis_bag)
```

Random Forest Method:
```{r}
set.seed(1997)

# Creates various random forest models 
randomForest(diagnosis_form, data = train_data[c(-1,-3)], mtry = 1, ntree = 201)
randomForest(diagnosis_form, data = train_data[c(-1,-3)], mtry = 2, ntree = 201)
randomForest(diagnosis_form, data = train_data[c(-1,-3)], mtry = 3, ntree = 201)
randomForest(diagnosis_form, data = train_data[c(-1,-3)], mtry = 4, ntree = 201) 
randomForest(diagnosis_form, data = train_data[c(-1,-3)], mtry = 5, ntree = 201) #best model
randomForest(diagnosis_form, data = train_data[c(-1,-3)], mtry = 6, ntree = 201)
randomForest(diagnosis_form, data = train_data[c(-1,-3)], mtry = 7, ntree = 201)
randomForest(diagnosis_form, data = train_data[c(-1,-3)], mtry = 8, ntree = 201)
randomForest(diagnosis_form, data = train_data[c(-1,-3)], mtry = 9, ntree = 201)
```

Best model for Random Forest Method
```{r}
set.seed(1997)

# Choose the best random forest model, # note: m = 5
diagnosis_forest <- randomForest(diagnosis_form, data = train_data[c(-1,-3)], mtry = 5, ntree = 201)
# Creates predictions for diagnosis using random forest
diagnosis_forest_preds <- predict(diagnosis_forest, newdata = test_data[c(-1,-2,-3)])
# Creates Confusion Matrix
confusionMatrix(diagnosis_forest_preds, test_data$diagnosis, mode = "everything", positive = 'M')
```


## Classification Algorithm using K-Nearest Neighbors (KNN) method

KNN Method: (uses optimal K by rule of thumb) 
```{r}
set.seed(1997)

# Computes Optimal K value by rule of thumb
optimal_k_rot <- sqrt(NROW(train_data))
knn21 <- knn(train = train_data[c(-1,-2,-3)], test = test_data[c(-1,-2,-3)], cl=train_data$diagnosis, k= optimal_k_rot)
# Creates Confusion Matrix
confusionMatrix(table(knn21, test_data$diagnosis),mode = "everything", positive = 'M')
```

Examine KNN Performance among each K value
```{r}
set.seed(1997)
i=1; optimal_k=1

for (i in 1:21){
  model_knn <- knn(train_data[c(-1,-2,-3)], test = test_data[c(-1,-2,-3)], cl=train_data$diagnosis, k=i)
  
  optimal_k[i] <- 100 * sum(test_data$diagnosis == model_knn)/NROW(test_data$diagnosis)
  k=i
  # prints values
  cat(k,'=',optimal_k[i],'')
}

# Plots Accuracy level vs K value
plot(optimal_k, type="b", xlab="K- Value",ylab="Accuracy level")
```
Based on the plot results, the optimal K-value is when K=14.

KNN Method: (uses optimal K by simulation)
```{r}
set.seed(1997)
knn14 <- knn(train = train_data[c(-1,-2,-3)], test = test_data[c(-1,-2,-3)], cl=train_data$diagnosis, k= 14)
# Creates Confusion Matrix
confusionMatrix(table(knn14, test_data$diagnosis), mode = "everything", positive = 'M')
```
As a result, the best fitted model was when K = 14.


Examine misclassified observations 
```{r}
misclassified_obs <- which(knn14 != test_data$diagnosis)
fna_tidy_rescale[misclassified_obs,]
```
As a result, the 4 false-negatives (FN) have probabilities greater than 0.8, whereas the 1 false-positive (FP) has a probability of 0.545. One of the four FN even has a probability of 1.0. Further investigation is needed into understanding this phenomena.


## ROC Curves for All Methods

Decision Tree Method
```{r}
set.seed(1997)

diagnosis_tree_rocpreds <- predict(diagnosis_tree, newdata = test_data[c(-1,-2,-3)], type = "prob")
roc_tree_preds <- prediction(diagnosis_tree_rocpreds[,2], test_data$diagnosis)
roc_tree_perf <- performance(roc_tree_preds, "tpr", "fpr")
plot(roc_tree_perf, avg= "threshold", colorize=T, lwd=3, main="ROC curve for Decision Tree")
```

Bagging Method
```{r}
set.seed(1997)

diagnosis_bag_rocpreds <- predict(diagnosis_bag, newdata = test_data[c(-1,-2,-3)], type = "prob")
roc_bag_preds <- prediction(diagnosis_bag_rocpreds[,2], test_data$diagnosis)
roc_bag_perf <- performance(roc_bag_preds, "tpr", "fpr")
plot(roc_bag_perf, avg= "threshold", colorize=T, lwd=3, main="ROC curve for Bagging")
```

Random Forest Method
```{r}
set.seed(1997)

diagnosis_forest_rocpreds <- predict(diagnosis_forest, newdata = test_data[c(-1,-2,-3)], type = "prob")
roc_forest_preds <- prediction(diagnosis_forest_rocpreds[,2], test_data$diagnosis)
roc_forest_perf <- performance(roc_forest_preds, "tpr", "fpr")
plot(roc_forest_perf, avg= "threshold", colorize=T, lwd=3, main="ROC curve for Random Forest")
```

KNN Method
```{r}
set.seed(1997)

diagnosis_knn_prob <- knn(train_data[c(-1,-2,-3)], test_data[c(-1,-2,-3)], cl = train_data$diagnosis_binary, k = 14, prob=TRUE)
# extracts the probabilities from the KNN method using the attribute function
prob <- attr(diagnosis_knn_prob, "prob")
# Since it takes majority voting, we must manually account for benign causes, which are defined as "0"
diagnosis_knn_rocpreds <- ifelse(diagnosis_knn_prob == "0", 1-prob, prob)
# plots ROC curve
roc_knn_preds <- prediction(diagnosis_knn_rocpreds, test_data$diagnosis)
roc_knn_perf <- performance(roc_knn_preds, "tpr", "fpr")
plot(roc_knn_perf, avg= "threshold", colorize=T, lwd=3, main="ROC curve for KNN")
```

Combining plot results of all four methods
```{r}
set.seed(1997)

# plot curves on same graph
plot(roc_tree_perf, col = "orange", main = "ROC Curves of each method", lwd =2)
plot(roc_bag_perf, add=T, col = "green", lwd =2)
plot(roc_forest_perf, add=T, col = "blue", lwd =2)
plot(roc_knn_perf, add=T, avg= "threshold", col = "purple", lwd =2)
abline(a = 0, b = 1, col = "red", lwd =2, lty=2)
legend(x = "bottomright",
       inset = 0.05, 
       legend = c(" decision tree","bagging","random forest","knn","pure chance"),
        col = c("orange","blue","green","purple", "red"),
       lty = c(1,1,1,1,2),
       lwd = 2,
       title = "Type of Method"
       )
```
Based on the ROC results, the best method in descending order was KNN, bagging, random forest, and decision tree method. Note that although random forest and decision tree accuracy were larger than bagging, their F1-scores however were lower in that order. Since the data is imbalance, we cannot just rely on accuracy but rather precision and recall, which can be evaluated using F1-score. In addition, the results for the best method in terms of precision remain the same. However, in terms of recall all of the methods performed the same with the exception of the decision tree method performing the worset.
